{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f992e30",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))  # 当前目录\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))  # 上一级目录\n",
    "sys.path.append(parent_dir)\n",
    "grandparent_dir = os.path.abspath(os.path.join(parent_dir, \"..\"))  # 上两级目录\n",
    "sys.path.append(grandparent_dir)\n",
    "\n",
    "import data_function\n",
    "import metrics\n",
    "import tools\n",
    "import utils\n",
    "\n",
    "# from test_case.ex_main.model import *\n",
    "# from test_case.ex_main.train_dataloader import getData\n",
    "from ex_main.model import *\n",
    "from ex_main.train_dataloader import getData\n",
    "from utils.config_plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88511461-de18-467a-b7d7-cd77052bf056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 09:28:38 INFO ##################################################\n",
      "2024-03-20 09:28:38 INFO Task: ReID_Task\n",
      "2024-03-20 09:28:38 INFO Using device: cuda\n",
      "2024-03-20 09:28:38 INFO Using data type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "ppath = \"/home/hy/project/reid/ex_main/\"\n",
    "\n",
    "# Config\n",
    "config_file_path = os.path.join(ppath, \"config.py\")\n",
    "config = utils.common.read_config_file(config_file_path)\n",
    "\n",
    "# Initialize a logger tool\n",
    "logger = utils.logger.Logger(config.outputs_path)\n",
    "logger.info(\"#\" * 50)\n",
    "logger.info(f\"Task: {config.taskname}\")\n",
    "logger.info(f\"Using device: {config.device}\")\n",
    "logger.info(f\"Using data type: {config.dtype}\")\n",
    "\n",
    "# Set environment\n",
    "random.seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "torch.manual_seed(config.seed)\n",
    "torch.cuda.manual_seed(config.seed)\n",
    "torch.cuda.manual_seed_all(config.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # The result cannot be reproduced when True\n",
    "\n",
    "vis_outputs_path = \"./results/vis/\"\n",
    "if os.path.exists(vis_outputs_path):\n",
    "    shutil.rmtree(vis_outputs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a281ac7-8994-4624-9c4c-0ec4a8e7b4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully load imagenet pre-trained resnet50-ibn model\n",
      "Successfully loaded pretrained weights from \"/home/hy/project/reid/ex_main/outputs/models/model_120.tar\"\n",
      "Model numbers of parameters: 34989120\n"
     ]
    }
   ],
   "source": [
    "# config.device = \"cpu\"\n",
    "config.test_batch_size = 512\n",
    "_, query_loader, gallery_loader, num_classes = getData(config=config)\n",
    "\n",
    "model = ReidNet(num_classes=num_classes, config=config, logger=logger).to(config.device)\n",
    "path = os.path.join(ppath, \"outputs/models/model_120.tar\")\n",
    "utils.network.load_network(model, path, config.device)\n",
    "print(\"Model numbers of parameters: {}\".format(utils.network.count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "524149bc-0ba1-429f-8389-567fa67bc4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features ...\n",
      "torch.Size([3368, 2048]) torch.Size([15913, 2048])\n",
      "Normalzing features with L2 norm ...\n"
     ]
    }
   ],
   "source": [
    "# CMC, mAP = metrics.test_function(\n",
    "#     model, query_loader, gallery_loader, config=config, logger=logger\n",
    "# )\n",
    "# message = (\n",
    "#     \"Testing: dataset_name: {} top1:{:.4f} top5:{:.4f} top10:{:.4f} mAP:{:.4f}\"\n",
    "# ).format(config.dataset_name, CMC[0], CMC[4], CMC[9], mAP)\n",
    "# logger.info(message)\n",
    "\n",
    "print(\"Loading features ...\")\n",
    "qf = torch.load(os.path.join(ppath, \"outputs/temps/query_features_market1501.pt\"))\n",
    "gf = torch.load(os.path.join(ppath, \"outputs/temps/gallery_features_market1501.pt\"))\n",
    "print(qf.shape, gf.shape)\n",
    "\n",
    "print(\"Normalzing features with L2 norm ...\")\n",
    "qf = F.normalize(qf, p=2, dim=1)\n",
    "gf = F.normalize(gf, p=2, dim=1)\n",
    "\n",
    "distmat, rank_results = metrics.distance.compute_distance_matrix(qf, gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e8304e-df18-41a9-ba5d-f236af5048d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_function.datasets.Market1501(root=config.dataset_path)\n",
    "\n",
    "# tools.visualize_ranked_results.visualize_ranked_results(\n",
    "#     distmat,\n",
    "#     [dataset.query, dataset.gallery],\n",
    "#     \"image\",\n",
    "#     width=128,\n",
    "#     height=256,\n",
    "#     save_dir=os.path.join(vis_outputs_path, \"ranked_results\"),\n",
    "#     topk=10,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a13f76e4-69cd-4b8f-9f0a-abe8002776be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing activation maps for dataset ...\n"
     ]
    }
   ],
   "source": [
    "def val_collate_fn(batch):\n",
    "    imgs, pids, camids, impath = zip(*batch)\n",
    "    return torch.stack(imgs, dim=0), pids, camids, impath\n",
    "\n",
    "\n",
    "hmap_loader = query_loader\n",
    "hmap_loader.collate_fn = val_collate_fn\n",
    "tools.visualize_actmap.visactmap(\n",
    "    model,\n",
    "    hmap_loader,\n",
    "    os.path.join(vis_outputs_path, \"hmap\"),\n",
    "    width=config.img_width,\n",
    "    height=config.img_height,\n",
    "    use_gpu=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
