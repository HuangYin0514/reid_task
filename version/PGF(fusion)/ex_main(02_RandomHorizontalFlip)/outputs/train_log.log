2024-03-08 10:34:55 INFO ##################################################
2024-03-08 10:34:55 INFO Task: PCB
2024-03-08 10:34:55 INFO Using device: cuda
2024-03-08 10:34:55 INFO Using data type: torch.float32
2024-03-08 10:34:55 INFO Number of GPUs: 1
2024-03-08 10:34:55 INFO GPU is_available: True
2024-03-08 10:34:55 INFO GPU name: NVIDIA GeForce RTX 3060
2024-03-08 10:34:55 INFO CUDA version: 12.1
2024-03-08 10:34:55 INFO Current device id: 0
2024-03-08 10:34:55 INFO ##################################################
2024-03-08 10:36:00 INFO Epoch 1/60	Training Loss: 35.1970	Time remaining is 1h:4m
2024-03-08 10:37:02 INFO Epoch 2/60	Training Loss: 30.7504	Time remaining is 1h:2m
2024-03-08 10:38:04 INFO Epoch 3/60	Training Loss: 26.7803	Time remaining is 1h:1m
2024-03-08 10:39:06 INFO Epoch 4/60	Training Loss: 23.1687	Time remaining is 0h:59m
2024-03-08 10:40:09 INFO Epoch 5/60	Training Loss: 20.2383	Time remaining is 0h:58m
2024-03-08 10:41:11 INFO Epoch 6/60	Training Loss: 17.8332	Time remaining is 0h:57m
2024-03-08 10:42:13 INFO Epoch 7/60	Training Loss: 15.9209	Time remaining is 0h:56m
2024-03-08 10:43:15 INFO Epoch 8/60	Training Loss: 14.4362	Time remaining is 0h:55m
2024-03-08 10:44:17 INFO Epoch 9/60	Training Loss: 13.0684	Time remaining is 0h:54m
2024-03-08 10:45:19 INFO Epoch 10/60	Training Loss: 12.1505	Time remaining is 0h:53m
2024-03-08 10:46:21 INFO Epoch 11/60	Training Loss: 11.3005	Time remaining is 0h:52m
2024-03-08 10:47:24 INFO Epoch 12/60	Training Loss: 10.6964	Time remaining is 0h:51m
2024-03-08 10:48:26 INFO Epoch 13/60	Training Loss: 10.0601	Time remaining is 0h:50m
2024-03-08 10:49:28 INFO Epoch 14/60	Training Loss: 9.6754	Time remaining is 0h:49m
2024-03-08 10:50:30 INFO Epoch 15/60	Training Loss: 9.1375	Time remaining is 0h:48m
2024-03-08 10:51:32 INFO Epoch 16/60	Training Loss: 8.7916	Time remaining is 0h:47m
2024-03-08 10:52:35 INFO Epoch 17/60	Training Loss: 8.7207	Time remaining is 0h:46m
2024-03-08 10:53:37 INFO Epoch 18/60	Training Loss: 8.3277	Time remaining is 0h:45m
2024-03-08 10:54:39 INFO Epoch 19/60	Training Loss: 8.0515	Time remaining is 0h:44m
2024-03-08 10:55:41 INFO Epoch 20/60	Training Loss: 7.9032	Time remaining is 0h:43m
2024-03-08 10:56:13 INFO Testing: dataset_name: market1501 top1:0.9047 top5:0.9614 top10:0.9751 mAP:0.7369
2024-03-08 10:57:15 INFO Epoch 21/60	Training Loss: 7.1116	Time remaining is 0h:42m
2024-03-08 10:58:17 INFO Epoch 22/60	Training Loss: 6.5302	Time remaining is 0h:41m
2024-03-08 10:59:19 INFO Epoch 23/60	Training Loss: 6.4248	Time remaining is 0h:40m
2024-03-08 11:00:21 INFO Epoch 24/60	Training Loss: 6.4301	Time remaining is 0h:39m
2024-03-08 11:01:24 INFO Epoch 25/60	Training Loss: 6.3439	Time remaining is 0h:38m
2024-03-08 11:02:26 INFO Epoch 26/60	Training Loss: 6.3315	Time remaining is 0h:37m
2024-03-08 11:03:28 INFO Epoch 27/60	Training Loss: 6.2936	Time remaining is 0h:36m
2024-03-08 11:04:30 INFO Epoch 28/60	Training Loss: 6.2432	Time remaining is 0h:35m
2024-03-08 11:05:33 INFO Epoch 29/60	Training Loss: 6.2562	Time remaining is 0h:34m
2024-03-08 11:06:35 INFO Epoch 30/60	Training Loss: 6.2327	Time remaining is 0h:33m
2024-03-08 11:07:37 INFO Epoch 31/60	Training Loss: 6.1957	Time remaining is 0h:32m
2024-03-08 11:08:40 INFO Epoch 32/60	Training Loss: 6.2139	Time remaining is 0h:31m
2024-03-08 11:09:42 INFO Epoch 33/60	Training Loss: 6.1938	Time remaining is 0h:29m
2024-03-08 11:10:45 INFO Epoch 34/60	Training Loss: 6.1866	Time remaining is 0h:28m
2024-03-08 11:11:47 INFO Epoch 35/60	Training Loss: 6.1449	Time remaining is 0h:27m
2024-03-08 11:12:49 INFO Epoch 36/60	Training Loss: 6.1632	Time remaining is 0h:26m
2024-03-08 11:13:52 INFO Epoch 37/60	Training Loss: 6.1478	Time remaining is 0h:25m
2024-03-08 11:14:54 INFO Epoch 38/60	Training Loss: 6.1454	Time remaining is 0h:24m
2024-03-08 11:15:57 INFO Epoch 39/60	Training Loss: 6.1391	Time remaining is 0h:23m
2024-03-08 11:16:59 INFO Epoch 40/60	Training Loss: 6.0866	Time remaining is 0h:22m
2024-03-08 11:17:30 INFO Testing: dataset_name: market1501 top1:0.9284 top5:0.9697 top10:0.9783 mAP:0.7892
2024-03-08 11:18:33 INFO Epoch 41/60	Training Loss: 6.1092	Time remaining is 0h:21m
2024-03-08 11:19:35 INFO Epoch 42/60	Training Loss: 6.0900	Time remaining is 0h:20m
2024-03-08 11:20:37 INFO Epoch 43/60	Training Loss: 6.0711	Time remaining is 0h:19m
2024-03-08 11:21:39 INFO Epoch 44/60	Training Loss: 6.1006	Time remaining is 0h:18m
2024-03-08 11:22:42 INFO Epoch 45/60	Training Loss: 6.0857	Time remaining is 0h:17m
2024-03-08 11:23:44 INFO Epoch 46/60	Training Loss: 6.1247	Time remaining is 0h:16m
2024-03-08 11:24:46 INFO Epoch 47/60	Training Loss: 6.0534	Time remaining is 0h:15m
2024-03-08 11:25:49 INFO Epoch 48/60	Training Loss: 6.0920	Time remaining is 0h:14m
2024-03-08 11:26:51 INFO Epoch 49/60	Training Loss: 6.0568	Time remaining is 0h:13m
2024-03-08 11:27:53 INFO Epoch 50/60	Training Loss: 6.0508	Time remaining is 0h:12m
2024-03-08 11:28:55 INFO Epoch 51/60	Training Loss: 6.1182	Time remaining is 0h:11m
2024-03-08 11:29:57 INFO Epoch 52/60	Training Loss: 6.0967	Time remaining is 0h:10m
2024-03-08 11:31:00 INFO Epoch 53/60	Training Loss: 6.0963	Time remaining is 0h:8m
2024-03-08 11:32:02 INFO Epoch 54/60	Training Loss: 6.0551	Time remaining is 0h:7m
2024-03-08 11:33:04 INFO Epoch 55/60	Training Loss: 6.0848	Time remaining is 0h:6m
2024-03-08 11:34:06 INFO Epoch 56/60	Training Loss: 6.0822	Time remaining is 0h:5m
2024-03-08 11:35:09 INFO Epoch 57/60	Training Loss: 6.0890	Time remaining is 0h:4m
2024-03-08 11:36:11 INFO Epoch 58/60	Training Loss: 6.0892	Time remaining is 0h:3m
2024-03-08 11:37:13 INFO Epoch 59/60	Training Loss: 6.0822	Time remaining is 0h:2m
2024-03-08 11:38:16 INFO Epoch 60/60	Training Loss: 6.0826	Time remaining is 0h:1m
2024-03-08 11:38:47 INFO Testing: dataset_name: market1501 top1:0.9287 top5:0.9712 top10:0.9786 mAP:0.7928
2024-03-08 11:38:47 INFO The running time of training: 3.83191e+03 s
2024-03-08 11:39:03 INFO ##################################################
2024-03-08 11:39:03 INFO Task: PCB
2024-03-08 11:39:03 INFO Using device: cuda
2024-03-08 11:39:03 INFO Using data type: torch.float32
