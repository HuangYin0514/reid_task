2024-03-10 10:41:00 INFO ##################################################
2024-03-10 10:41:00 INFO Task: ReID_Task
2024-03-10 10:41:00 INFO Using device: cuda
2024-03-10 10:41:00 INFO Using data type: torch.float32
2024-03-10 10:41:00 INFO Number of GPUs: 1
2024-03-10 10:41:00 INFO GPU is_available: True
2024-03-10 10:41:00 INFO GPU name: NVIDIA GeForce RTX 3060
2024-03-10 10:41:00 INFO CUDA version: 12.1
2024-03-10 10:41:00 INFO Current device id: 0
2024-03-10 10:41:00 INFO ##################################################
2024-03-10 10:42:17 INFO Epoch 1/120	Training Loss: 8.2213	Time remaining is 2h:32m
2024-03-10 10:43:31 INFO Epoch 2/120	Training Loss: 7.4291	Time remaining is 2h:29m
2024-03-10 10:44:46 INFO Epoch 3/120	Training Loss: 6.0354	Time remaining is 2h:27m
2024-03-10 10:46:01 INFO Epoch 4/120	Training Loss: 4.4982	Time remaining is 2h:26m
2024-03-10 10:47:16 INFO Epoch 5/120	Training Loss: 3.2795	Time remaining is 2h:25m
2024-03-10 10:48:30 INFO Epoch 6/120	Training Loss: 2.5318	Time remaining is 2h:23m
2024-03-10 10:49:44 INFO Epoch 7/120	Training Loss: 2.1319	Time remaining is 2h:22m
2024-03-10 10:50:59 INFO Epoch 8/120	Training Loss: 1.9329	Time remaining is 2h:21m
2024-03-10 10:52:13 INFO Epoch 9/120	Training Loss: 1.8383	Time remaining is 2h:19m
2024-03-10 10:53:28 INFO Epoch 10/120	Training Loss: 1.7791	Time remaining is 2h:18m
2024-03-10 10:54:43 INFO Epoch 11/120	Training Loss: 1.7494	Time remaining is 2h:17m
2024-03-10 10:55:58 INFO Epoch 12/120	Training Loss: 1.6681	Time remaining is 2h:16m
2024-03-10 10:57:12 INFO Epoch 13/120	Training Loss: 1.5982	Time remaining is 2h:14m
2024-03-10 10:58:28 INFO Epoch 14/120	Training Loss: 1.5565	Time remaining is 2h:13m
2024-03-10 10:59:42 INFO Epoch 15/120	Training Loss: 1.5283	Time remaining is 2h:12m
2024-03-10 11:00:57 INFO Epoch 16/120	Training Loss: 1.5216	Time remaining is 2h:11m
2024-03-10 11:02:11 INFO Epoch 17/120	Training Loss: 1.5199	Time remaining is 2h:10m
2024-03-10 11:03:26 INFO Epoch 18/120	Training Loss: 1.5065	Time remaining is 2h:8m
2024-03-10 11:04:40 INFO Epoch 19/120	Training Loss: 1.5085	Time remaining is 2h:7m
2024-03-10 11:05:55 INFO Epoch 20/120	Training Loss: 1.5008	Time remaining is 2h:6m
2024-03-10 11:07:10 INFO Epoch 21/120	Training Loss: 1.5088	Time remaining is 2h:4m
2024-03-10 11:08:24 INFO Epoch 22/120	Training Loss: 1.5154	Time remaining is 2h:3m
2024-03-10 11:09:38 INFO Epoch 23/120	Training Loss: 1.5036	Time remaining is 2h:2m
2024-03-10 11:10:52 INFO Epoch 24/120	Training Loss: 1.5294	Time remaining is 2h:1m
2024-03-10 11:12:07 INFO Epoch 25/120	Training Loss: 1.5354	Time remaining is 1h:59m
2024-03-10 11:13:22 INFO Epoch 26/120	Training Loss: 1.5413	Time remaining is 1h:58m
2024-03-10 11:14:36 INFO Epoch 27/120	Training Loss: 1.5239	Time remaining is 1h:57m
2024-03-10 11:15:51 INFO Epoch 28/120	Training Loss: 1.5195	Time remaining is 1h:56m
2024-03-10 11:17:05 INFO Epoch 29/120	Training Loss: 1.5166	Time remaining is 1h:54m
2024-03-10 11:18:19 INFO Epoch 30/120	Training Loss: 1.5117	Time remaining is 1h:53m
2024-03-10 11:19:34 INFO Epoch 31/120	Training Loss: 1.5078	Time remaining is 1h:52m
2024-03-10 11:20:48 INFO Epoch 32/120	Training Loss: 1.5174	Time remaining is 1h:51m
2024-03-10 11:22:03 INFO Epoch 33/120	Training Loss: 1.5214	Time remaining is 1h:49m
2024-03-10 11:23:18 INFO Epoch 34/120	Training Loss: 1.5223	Time remaining is 1h:48m
2024-03-10 11:24:32 INFO Epoch 35/120	Training Loss: 1.5186	Time remaining is 1h:47m
2024-03-10 11:25:47 INFO Epoch 36/120	Training Loss: 1.5089	Time remaining is 1h:46m
2024-03-10 11:27:02 INFO Epoch 37/120	Training Loss: 1.5063	Time remaining is 1h:44m
2024-03-10 11:28:16 INFO Epoch 38/120	Training Loss: 1.5150	Time remaining is 1h:43m
2024-03-10 11:29:31 INFO Epoch 39/120	Training Loss: 1.5136	Time remaining is 1h:42m
2024-03-10 11:30:45 INFO Epoch 40/120	Training Loss: 1.5101	Time remaining is 1h:41m
2024-03-10 11:32:00 INFO Epoch 41/120	Training Loss: 1.4443	Time remaining is 1h:39m
2024-03-10 11:33:14 INFO Epoch 42/120	Training Loss: 1.3813	Time remaining is 1h:38m
2024-03-10 11:34:28 INFO Epoch 43/120	Training Loss: 1.3746	Time remaining is 1h:37m
2024-03-10 11:35:43 INFO Epoch 44/120	Training Loss: 1.3675	Time remaining is 1h:36m
2024-03-10 11:36:57 INFO Epoch 45/120	Training Loss: 1.3618	Time remaining is 1h:34m
2024-03-10 11:38:12 INFO Epoch 46/120	Training Loss: 1.3587	Time remaining is 1h:33m
2024-03-10 11:39:26 INFO Epoch 47/120	Training Loss: 1.3472	Time remaining is 1h:32m
2024-03-10 11:40:41 INFO Epoch 48/120	Training Loss: 1.3530	Time remaining is 1h:31m
2024-03-10 11:41:55 INFO Epoch 49/120	Training Loss: 1.3437	Time remaining is 1h:29m
2024-03-10 11:43:09 INFO Epoch 50/120	Training Loss: 1.3467	Time remaining is 1h:28m
2024-03-10 11:44:24 INFO Epoch 51/120	Training Loss: 1.3377	Time remaining is 1h:27m
2024-03-10 11:45:38 INFO Epoch 52/120	Training Loss: 1.3439	Time remaining is 1h:26m
2024-03-10 11:46:53 INFO Epoch 53/120	Training Loss: 1.3435	Time remaining is 1h:24m
2024-03-10 11:48:07 INFO Epoch 54/120	Training Loss: 1.3402	Time remaining is 1h:23m
2024-03-10 11:49:22 INFO Epoch 55/120	Training Loss: 1.3422	Time remaining is 1h:22m
2024-03-10 11:50:37 INFO Epoch 56/120	Training Loss: 1.3402	Time remaining is 1h:21m
2024-03-10 11:51:51 INFO Epoch 57/120	Training Loss: 1.3302	Time remaining is 1h:20m
2024-03-10 11:53:05 INFO Epoch 58/120	Training Loss: 1.3365	Time remaining is 1h:18m
2024-03-10 11:54:20 INFO Epoch 59/120	Training Loss: 1.3364	Time remaining is 1h:17m
2024-03-10 11:55:34 INFO Epoch 60/120	Training Loss: 1.3350	Time remaining is 1h:16m
2024-03-10 11:56:49 INFO Epoch 61/120	Training Loss: 1.3356	Time remaining is 1h:15m
2024-03-10 11:58:03 INFO Epoch 62/120	Training Loss: 1.3335	Time remaining is 1h:13m
2024-03-10 11:59:18 INFO Epoch 63/120	Training Loss: 1.3321	Time remaining is 1h:12m
2024-03-10 12:00:32 INFO Epoch 64/120	Training Loss: 1.3321	Time remaining is 1h:11m
2024-03-10 12:01:47 INFO Epoch 65/120	Training Loss: 1.3301	Time remaining is 1h:10m
2024-03-10 12:03:02 INFO Epoch 66/120	Training Loss: 1.3293	Time remaining is 1h:8m
2024-03-10 12:04:17 INFO Epoch 67/120	Training Loss: 1.3380	Time remaining is 1h:7m
2024-03-10 12:05:31 INFO Epoch 68/120	Training Loss: 1.3307	Time remaining is 1h:6m
2024-03-10 12:06:46 INFO Epoch 69/120	Training Loss: 1.3244	Time remaining is 1h:5m
2024-03-10 12:08:01 INFO Epoch 70/120	Training Loss: 1.3272	Time remaining is 1h:3m
2024-03-10 12:09:15 INFO Epoch 71/120	Training Loss: 1.3250	Time remaining is 1h:2m
2024-03-10 12:10:30 INFO Epoch 72/120	Training Loss: 1.3202	Time remaining is 1h:1m
2024-03-10 12:11:45 INFO Epoch 73/120	Training Loss: 1.3179	Time remaining is 0h:60m
2024-03-10 12:13:00 INFO Epoch 74/120	Training Loss: 1.3111	Time remaining is 0h:58m
2024-03-10 12:14:14 INFO Epoch 75/120	Training Loss: 1.3109	Time remaining is 0h:57m
2024-03-10 12:15:28 INFO Epoch 76/120	Training Loss: 1.3081	Time remaining is 0h:56m
2024-03-10 12:16:43 INFO Epoch 77/120	Training Loss: 1.3158	Time remaining is 0h:55m
2024-03-10 12:17:57 INFO Epoch 78/120	Training Loss: 1.3087	Time remaining is 0h:53m
2024-03-10 12:19:12 INFO Epoch 79/120	Training Loss: 1.3155	Time remaining is 0h:52m
2024-03-10 12:20:26 INFO Epoch 80/120	Training Loss: 1.3150	Time remaining is 0h:51m
2024-03-10 12:21:41 INFO Epoch 81/120	Training Loss: 1.3141	Time remaining is 0h:50m
2024-03-10 12:22:56 INFO Epoch 82/120	Training Loss: 1.3148	Time remaining is 0h:48m
2024-03-10 12:24:10 INFO Epoch 83/120	Training Loss: 1.3132	Time remaining is 0h:47m
2024-03-10 12:25:25 INFO Epoch 84/120	Training Loss: 1.3131	Time remaining is 0h:46m
2024-03-10 12:26:40 INFO Epoch 85/120	Training Loss: 1.3147	Time remaining is 0h:45m
2024-03-10 12:27:54 INFO Epoch 86/120	Training Loss: 1.3139	Time remaining is 0h:44m
2024-03-10 12:29:09 INFO Epoch 87/120	Training Loss: 1.3124	Time remaining is 0h:42m
2024-03-10 12:30:23 INFO Epoch 88/120	Training Loss: 1.3054	Time remaining is 0h:41m
2024-03-10 12:31:37 INFO Epoch 89/120	Training Loss: 1.3125	Time remaining is 0h:40m
2024-03-10 12:32:52 INFO Epoch 90/120	Training Loss: 1.3114	Time remaining is 0h:39m
2024-03-10 12:33:30 INFO Testing: dataset_name: market1501 top1:0.9498 top5:0.9834 top10:0.9893 mAP:0.8701
2024-03-10 12:34:44 INFO Epoch 91/120	Training Loss: 1.3122	Time remaining is 0h:37m
2024-03-10 12:35:58 INFO Epoch 92/120	Training Loss: 1.3065	Time remaining is 0h:36m
2024-03-10 12:37:13 INFO Epoch 93/120	Training Loss: 1.3131	Time remaining is 0h:35m
2024-03-10 12:38:27 INFO Epoch 94/120	Training Loss: 1.3117	Time remaining is 0h:34m
2024-03-10 12:39:41 INFO Epoch 95/120	Training Loss: 1.3044	Time remaining is 0h:32m
2024-03-10 12:40:56 INFO Epoch 96/120	Training Loss: 1.3129	Time remaining is 0h:31m
2024-03-10 12:42:10 INFO Epoch 97/120	Training Loss: 1.3032	Time remaining is 0h:30m
2024-03-10 12:43:24 INFO Epoch 98/120	Training Loss: 1.3123	Time remaining is 0h:29m
2024-03-10 12:44:39 INFO Epoch 99/120	Training Loss: 1.3105	Time remaining is 0h:27m
2024-03-10 12:45:53 INFO Epoch 100/120	Training Loss: 1.3088	Time remaining is 0h:26m
2024-03-10 12:46:30 INFO Testing: dataset_name: market1501 top1:0.9477 top5:0.9831 top10:0.9899 mAP:0.8683
2024-03-10 12:47:45 INFO Epoch 101/120	Training Loss: 1.3118	Time remaining is 0h:25m
2024-03-10 12:48:59 INFO Epoch 102/120	Training Loss: 1.3099	Time remaining is 0h:24m
2024-03-10 12:50:13 INFO Epoch 103/120	Training Loss: 1.3087	Time remaining is 0h:23m
2024-03-10 12:51:28 INFO Epoch 104/120	Training Loss: 1.3089	Time remaining is 0h:21m
2024-03-10 12:52:43 INFO Epoch 105/120	Training Loss: 1.3159	Time remaining is 0h:20m
2024-03-10 12:53:57 INFO Epoch 106/120	Training Loss: 1.3097	Time remaining is 0h:19m
2024-03-10 12:55:11 INFO Epoch 107/120	Training Loss: 1.3041	Time remaining is 0h:18m
2024-03-10 12:56:25 INFO Epoch 108/120	Training Loss: 1.3110	Time remaining is 0h:16m
2024-03-10 12:57:40 INFO Epoch 109/120	Training Loss: 1.3091	Time remaining is 0h:15m
2024-03-10 12:58:54 INFO Epoch 110/120	Training Loss: 1.3096	Time remaining is 0h:14m
2024-03-10 12:59:32 INFO Testing: dataset_name: market1501 top1:0.9492 top5:0.9840 top10:0.9902 mAP:0.8715
2024-03-10 13:00:46 INFO Epoch 111/120	Training Loss: 1.3016	Time remaining is 0h:13m
2024-03-10 13:02:00 INFO Epoch 112/120	Training Loss: 1.3087	Time remaining is 0h:11m
2024-03-10 13:03:15 INFO Epoch 113/120	Training Loss: 1.3088	Time remaining is 0h:10m
2024-03-10 13:04:29 INFO Epoch 114/120	Training Loss: 1.3022	Time remaining is 0h:9m
2024-03-10 13:05:44 INFO Epoch 115/120	Training Loss: 1.3154	Time remaining is 0h:8m
2024-03-10 13:06:59 INFO Epoch 116/120	Training Loss: 1.3080	Time remaining is 0h:6m
2024-03-10 13:08:13 INFO Epoch 117/120	Training Loss: 1.3094	Time remaining is 0h:5m
2024-03-10 13:09:27 INFO Epoch 118/120	Training Loss: 1.3077	Time remaining is 0h:4m
2024-03-10 13:10:42 INFO Epoch 119/120	Training Loss: 1.3150	Time remaining is 0h:3m
2024-03-10 13:11:56 INFO Epoch 120/120	Training Loss: 1.3004	Time remaining is 0h:1m
2024-03-10 13:12:33 INFO Testing: dataset_name: market1501 top1:0.9507 top5:0.9825 top10:0.9890 mAP:0.8720
2024-03-10 13:12:34 INFO The running time of training: 9.09372e+03 s
2024-03-10 16:06:45 INFO ##################################################
2024-03-10 16:06:45 INFO Task: ReID_Task
2024-03-10 16:06:45 INFO Using device: cuda
2024-03-10 16:06:45 INFO Using data type: torch.float32
2024-03-10 16:13:44 INFO ##################################################
2024-03-10 16:13:44 INFO Task: ReID_Task
2024-03-10 16:13:44 INFO Using device: cuda
2024-03-10 16:13:44 INFO Using data type: torch.float32
2024-03-10 16:14:46 INFO ##################################################
2024-03-10 16:14:46 INFO Task: ReID_Task
2024-03-10 16:14:46 INFO Using device: cuda
2024-03-10 16:14:46 INFO Using data type: torch.float32
2024-03-10 16:16:04 INFO ##################################################
2024-03-10 16:16:04 INFO Task: ReID_Task
2024-03-10 16:16:04 INFO Using device: cuda
2024-03-10 16:16:04 INFO Using data type: torch.float32
2024-03-10 16:18:32 INFO ##################################################
2024-03-10 16:18:32 INFO Task: ReID_Task
2024-03-10 16:18:32 INFO Using device: cuda
2024-03-10 16:18:32 INFO Using data type: torch.float32
